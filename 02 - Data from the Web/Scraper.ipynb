{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 - Helpers and constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base URL for isa.epfl.ch public report searches\n",
    "isa_base_url = 'http://isa.epfl.ch/imoniteur_ISAP/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper for creating search path\n",
    "def isa_url(path):\n",
    "    return isa_base_url + path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page(url, params=None):\n",
    "    # Use requests to GET the isa search home page\n",
    "    r = requests.get(url, params)\n",
    "    if r.status_code is not 200: # Check the request completed\n",
    "        print(\"Something went wrong. Res.status_code = \" + str(r.status_code))\n",
    "        return None\n",
    "    # Extract the HTML as text ...\n",
    "    html = r.text\n",
    "    # ... so it can be parsed by BeautifulSoup\n",
    "    return BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Scraper Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to fetch all the data from ISA.\n",
    "\n",
    "To do this, we will have to scrape the respective frames that ISA serves for the form and then the search results. Steps are detailed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Full constructed url for ISA search\n",
    "isa_home_url = isa_url('%21gedpublicreports.htm?ww_i_reportmodel=133685247')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the form URL from the home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_soup = get_page(isa_home_url)\n",
    "# home_soup # debug print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the form frame\n",
    "toc_frame = home_soup.find('frame', attrs={'name': 'toc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!GEDPUBLICREPORTS.filter?ww_i_reportModel=133685247'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the form's URL\n",
    "toc_frame_url = toc_frame.attrs['src']\n",
    "toc_frame_url # Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Repeat previous process for the form's frame\n",
    "toc_url = isa_url(toc_frame_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toc_soup = get_page(toc_url)\n",
    "# toc_soup # debug print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the form itself within the page\n",
    "form_elem = toc_soup.find('form', attrs={'name': 'f'}) # The form's name is a heuristic, read from the page's source\n",
    "# print(form_elem.prettify()) # Debug print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.filter'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the form's action on validation\n",
    "form_action = form_elem['action']\n",
    "form_action_url = isa_url(form_action)\n",
    "form_action_url # Debug print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a payload dictionary with all the parameters expected by ISA's API endpoint\n",
    "\n",
    "# /!\\ By default we will request all possibilities from the endpoint, and then filter. /!\\ #\n",
    "\n",
    "# Example requests for specific academic or pedagogic periods are left FYI.\n",
    "\n",
    "payload = {\n",
    "    'ww_b_list': '1',\n",
    "    'ww_i_reportmodel': '133685247',\n",
    "    'ww_c_langue': '',\n",
    "    \n",
    "    # Format = html\n",
    "    'ww_i_reportModelXsl': '133685270', \n",
    "    \n",
    "    # Faculty = { Informatique : 249847 }\n",
    "    'zz_x_UNITE_ACAD': 'Informatique',\n",
    "    'ww_x_UNITE_ACAD': '249847',\n",
    "    \n",
    "    # Academic Period = { '' : null } if we want all possible periods\n",
    "    #                 = { '2016-2017' : 355925344 } for a specific year\n",
    "    'zz_x_PERIODE_ACAD': '',\n",
    "    'ww_x_PERIODE_ACAD': 'null',\n",
    "\n",
    "    \n",
    "    # Pedagogic Period = { '' : null } if we want all possible periods\n",
    "    #                  = { 'Bachelor semestre 1' : 249108 } for a specific period\n",
    "    'zz_x_PERIODE_PEDAGO': '',\n",
    "    'ww_x_PERIODE_PEDAGO': 'null',\n",
    "    \n",
    "    # Winter or summer semesters\n",
    "    'zz_x_HIVERETE': '',\n",
    "    'ww_x_HIVERETE': 'null',\n",
    "    \n",
    "    'dummy': 'ok'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in the form and parse the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the result\n",
    "form_result_soup = get_page(form_action_url, params=payload)\n",
    "# form_result_soup.prettify() # Debug print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the links from the list of results\n",
    "all_links = form_result_soup('a', class_='ww_x_GPS')\n",
    "# all_links # Debug print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the links in a dictionary. Some cleaning is applied, such as whitespace stripping\n",
    "# Note : removing 'Tous' allows us to iterate and filter independently each result\n",
    "#        instead of an aggregate HTML table which would be much more painful to parse\n",
    "links = [{'text': link.text.strip(), 'url': link.attrs['onclick']} for link in all_links if link.text.strip() != 'Tous' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each link,the page loads the respective results with the following on-click action :\n",
    "\n",
    "```\n",
    "loadReport('ww_x_GPS=2021043255');return false;\n",
    "```\n",
    "\n",
    "We will use the following function ```parse_url()``` to extract the ```ww_x_GPS``` parameter expected by the API to return the desired information about the students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_url_pattern = r\"\"\"'(\\w+)=(\\d+)'\"\"\"\n",
    "parse_url_re = re.compile(parse_url_pattern)\n",
    "\n",
    "def parse_url(url):\n",
    "    match = re.search(parse_url_pattern, url)\n",
    "\n",
    "    if match == None:\n",
    "        print('parse_url: parsing failure: ' + url)\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'key': match.group(1),\n",
    "        'value': match.group(2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list itself must be parsed to extract information regarding section, academic year, pedagogic period. The format is the following :\n",
    "\n",
    "```\n",
    "Informatique, 2016-2017, Bachelor semestre 1\n",
    "```\n",
    "\n",
    "We call an element of the list an item, and it will be parsed by the following ```parse_item()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_item_pattern = r\"\"\"([^,]+),\\s*(\\d+)-(\\d+),\\s*([\\w\\s]+)\"\"\"\n",
    "parse_item_re = re.compile(parse_item_pattern)\n",
    "\n",
    "def parse_item(item, url, payload):\n",
    "    match = re.match(parse_item_re, item)\n",
    "    \n",
    "    if match == None:\n",
    "        print('parse_item: parsing failure: ' + item)\n",
    "        return None\n",
    "    \n",
    "    parsed_url = parse_url(url)\n",
    "    \n",
    "    if parsed_url == None:\n",
    "        return None\n",
    "    \n",
    "    params = payload.copy()\n",
    "    params[parsed_url['key']] = parsed_url['value']\n",
    "    \n",
    "    return {\n",
    "        'section': match.group(1),\n",
    "        'semester': match.group(4),\n",
    "        'year': {\n",
    "            'start': match.group(2),\n",
    "            'end': match.group(3)\n",
    "        },\n",
    "        'params': params\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can now parse the list of results and extract the final URLs to the student enrollment information\n",
    "items = [parse_item(link['text'], link['url'], payload) for link in links]\n",
    "# items # Debug print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Going through the years to extract the list of enrolled students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_page_url = isa_url('!GEDPUBLICREPORTS.html')\n",
    "\n",
    "res = get_page(list_page_url, items[0]['params'])\n",
    "# res # Debug print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
